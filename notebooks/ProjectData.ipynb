{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273ca581-cce8-4a9f-a705-dba2c4d9a700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.35.39)\n",
      "Requirement already satisfied: gitpython in /opt/conda/lib/python3.11/site-packages (3.1.43)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.39 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.35.39)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython) (4.0.11)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.36.0,>=1.35.39->boto3) (1.26.19)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas boto3 gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ecd5b39-abbe-446f-aea8-96f75f01740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Zip Code      Price  Beds  Baths  Living Space                Address  \\\n",
      "0     10013  3999000.0     2      3          1967      74 GRAND ST APT 3   \n",
      "1     10013  3999000.0     2      3          1967      74 GRAND ST APT 3   \n",
      "2     10014  1650000.0     1      1           718  140 CHARLES ST APT 4D   \n",
      "3     10014   760000.0     3      2          1538            38 JONES ST   \n",
      "4     10014  1100000.0     1      1           600   81 BEDFORD ST APT 3F   \n",
      "\n",
      "       City     State  Zip Code Population  Zip Code Density    County  \\\n",
      "0  New York  New York                29563           20967.9  New York   \n",
      "1  New York  New York                29563           20967.9  New York   \n",
      "2  New York  New York                29815           23740.9  New York   \n",
      "3  New York  New York                29815           23740.9  New York   \n",
      "4  New York  New York                29815           23740.9  New York   \n",
      "\n",
      "   Median Household Income  Latitude  Longitude  \n",
      "0                 370046.0  40.72001  -74.00472  \n",
      "1                 370046.0  40.72001  -74.00472  \n",
      "2                 249880.0  40.73407  -74.00601  \n",
      "3                 249880.0  40.73407  -74.00601  \n",
      "4                 249880.0  40.73407  -74.00601  \n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Specify the S3 bucket name\n",
    "bucket_name = 'christimoncriefbucket-v2'\n",
    "\n",
    "# List of files in S3\n",
    "files_in_s3 = ['realtor-data.zip.csv', 'KC_housing_data.csv', \n",
    "               'House Price Prediction Dataset.csv', 'American_Housing_Data_20231209.csv']\n",
    "\n",
    "# Function to read CSV files from S3\n",
    "def read_s3_csv(file_key):\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    return pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "# Example: Reading one of the files\n",
    "american_housing_data = read_s3_csv('American_Housing_Data_20231209.csv')\n",
    "print(american_housing_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc21bf9-79d2-4ea1-9a65-a753ad6532e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Housing Data:\n",
      "   Zip Code      Price  Beds  Baths  Living Space                Address  \\\n",
      "0     10013  3999000.0     2      3          1967      74 GRAND ST APT 3   \n",
      "1     10013  3999000.0     2      3          1967      74 GRAND ST APT 3   \n",
      "2     10014  1650000.0     1      1           718  140 CHARLES ST APT 4D   \n",
      "3     10014   760000.0     3      2          1538            38 JONES ST   \n",
      "4     10014  1100000.0     1      1           600   81 BEDFORD ST APT 3F   \n",
      "\n",
      "       City     State  Zip Code Population  Zip Code Density    County  \\\n",
      "0  New York  New York                29563           20967.9  New York   \n",
      "1  New York  New York                29563           20967.9  New York   \n",
      "2  New York  New York                29815           23740.9  New York   \n",
      "3  New York  New York                29815           23740.9  New York   \n",
      "4  New York  New York                29815           23740.9  New York   \n",
      "\n",
      "   Median Household Income  Latitude  Longitude  \n",
      "0                 370046.0  40.72001  -74.00472  \n",
      "1                 370046.0  40.72001  -74.00472  \n",
      "2                 249880.0  40.73407  -74.00601  \n",
      "3                 249880.0  40.73407  -74.00601  \n",
      "4                 249880.0  40.73407  -74.00601   \n",
      "\n",
      "KC Housing Data:\n",
      "                  date      price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
      "0  2014-05-02 00:00:00   313000.0       3.0       1.50         1340      7912   \n",
      "1  2014-05-02 00:00:00  2384000.0       5.0       2.50         3650      9050   \n",
      "2  2014-05-02 00:00:00   342000.0       3.0       2.00         1930     11947   \n",
      "3  2014-05-02 00:00:00   420000.0       3.0       2.25         2000      8030   \n",
      "4  2014-05-02 00:00:00   550000.0       4.0       2.50         1940     10500   \n",
      "\n",
      "   floors  waterfront  view  condition  sqft_above  sqft_basement  yr_built  \\\n",
      "0     1.5           0     0          3        1340              0      1955   \n",
      "1     2.0           0     4          5        3370            280      1921   \n",
      "2     1.0           0     0          4        1930              0      1966   \n",
      "3     1.0           0     0          4        1000           1000      1963   \n",
      "4     1.0           0     0          4        1140            800      1976   \n",
      "\n",
      "   yr_renovated                    street       city  statezip country  \n",
      "0          2005      18810 Densmore Ave N  Shoreline  WA 98133     USA  \n",
      "1             0           709 W Blaine St    Seattle  WA 98119     USA  \n",
      "2             0  26206-26214 143rd Ave SE       Kent  WA 98042     USA  \n",
      "3             0           857 170th Pl NE   Bellevue  WA 98008     USA  \n",
      "4          1992         9105 170th Ave NE    Redmond  WA 98052     USA   \n",
      "\n",
      "House Price Prediction Data:\n",
      "   Id  Area  Bedrooms  Bathrooms  Floors  YearBuilt  Location  Condition  \\\n",
      "0   1  1360         5          4       3       1970  Downtown  Excellent   \n",
      "1   2  4272         5          4       3       1958  Downtown  Excellent   \n",
      "2   3  3592         2          2       3       1938  Downtown       Good   \n",
      "3   4   966         4          2       2       1902  Suburban       Fair   \n",
      "4   5  4926         1          4       2       1975  Downtown       Fair   \n",
      "\n",
      "  Garage   Price  \n",
      "0     No  149919  \n",
      "1     No  424998  \n",
      "2     No  266746  \n",
      "3    Yes  244020  \n",
      "4    Yes  636056   \n",
      "\n",
      "Realtor Data:\n",
      "   brokered_by    status     price  bed  bath  acre_lot     street  \\\n",
      "0     103378.0  for_sale  105000.0  3.0   2.0      0.12  1962661.0   \n",
      "1      52707.0  for_sale   80000.0  4.0   2.0      0.08  1902874.0   \n",
      "2     103379.0  for_sale   67000.0  2.0   1.0      0.15  1404990.0   \n",
      "3      31239.0  for_sale  145000.0  4.0   2.0      0.10  1947675.0   \n",
      "4      34632.0  for_sale   65000.0  6.0   2.0      0.05   331151.0   \n",
      "\n",
      "         city        state  zip_code  house_size prev_sold_date  \n",
      "0    Adjuntas  Puerto Rico     601.0       920.0            NaN  \n",
      "1    Adjuntas  Puerto Rico     601.0      1527.0            NaN  \n",
      "2  Juana Diaz  Puerto Rico     795.0       748.0            NaN  \n",
      "3       Ponce  Puerto Rico     731.0      1800.0            NaN  \n",
      "4    Mayaguez  Puerto Rico     680.0         NaN            NaN   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Specify the S3 bucket name\n",
    "bucket_name = 'christimoncriefbucket-v2'\n",
    "\n",
    "# List of files in S3\n",
    "files_in_s3 = ['realtor-data.zip.csv', 'KC_housing_data.csv', \n",
    "               'House Price Prediction Dataset.csv', 'American_Housing_Data_20231209.csv']\n",
    "\n",
    "# Function to read CSV files from S3\n",
    "def read_s3_csv(file_key):\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    return pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "# Reading all datasets\n",
    "american_housing_data = read_s3_csv('American_Housing_Data_20231209.csv')\n",
    "kc_housing_data = read_s3_csv('KC_housing_data.csv')\n",
    "house_price_data = read_s3_csv('House Price Prediction Dataset.csv')\n",
    "realtor_data = read_s3_csv('realtor-data.zip.csv')\n",
    "\n",
    "# Print the first few rows of each dataset\n",
    "print(\"American Housing Data:\")\n",
    "print(american_housing_data.head(), \"\\n\")\n",
    "\n",
    "print(\"KC Housing Data:\")\n",
    "print(kc_housing_data.head(), \"\\n\")\n",
    "\n",
    "print(\"House Price Prediction Data:\")\n",
    "print(house_price_data.head(), \"\\n\")\n",
    "\n",
    "print(\"Realtor Data:\")\n",
    "print(realtor_data.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cddcca5c-5a4d-4611-a135-919965e42398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns from American Housing Data\n",
    "columns_to_keep_ah = ['Zip Code', 'Price', 'Beds', 'Baths', 'Living Space', 'City', 'State', 'County']\n",
    "american_housing_data_cleaned = american_housing_data[columns_to_keep_ah]\n",
    "\n",
    "# Clean KC Housing Data\n",
    "columns_to_keep_kc = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'street', 'city', 'statezip']\n",
    "kc_housing_data_cleaned = kc_housing_data[columns_to_keep_kc]\n",
    "\n",
    "# Clean House Price Prediction Data\n",
    "columns_to_keep_hp = ['Area', 'Bedrooms', 'Bathrooms', 'Price']\n",
    "house_price_data_cleaned = house_price_data[columns_to_keep_hp]\n",
    "\n",
    "# Clean Realtor Data\n",
    "columns_to_keep_rd = ['price', 'bed', 'bath', 'acre_lot', 'city', 'state', 'zip_code']\n",
    "realtor_data_cleaned = realtor_data[columns_to_keep_rd]\n",
    "\n",
    "# Drop rows with missing values (optional, adjust based on your needs)\n",
    "american_housing_data_cleaned = american_housing_data_cleaned.dropna()\n",
    "kc_housing_data_cleaned = kc_housing_data_cleaned.dropna()\n",
    "house_price_data_cleaned = house_price_data_cleaned.dropna()\n",
    "realtor_data_cleaned = realtor_data_cleaned.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fbba669-b5aa-406a-9d67-e9cce64e29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the realtor dataset to 12,000 entries\n",
    "realtor_reduced = realtor_data_cleaned.sample(n=12000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abe9693-ee6d-4583-8fd9-0822fb77005e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned American Housing Data:\n",
      "   Zip Code      Price  Beds  Baths  Living Space      City     State  \\\n",
      "0     10013  3999000.0     2      3          1967  New York  New York   \n",
      "1     10013  3999000.0     2      3          1967  New York  New York   \n",
      "2     10014  1650000.0     1      1           718  New York  New York   \n",
      "3     10014   760000.0     3      2          1538  New York  New York   \n",
      "4     10014  1100000.0     1      1           600  New York  New York   \n",
      "\n",
      "     County  \n",
      "0  New York  \n",
      "1  New York  \n",
      "2  New York  \n",
      "3  New York  \n",
      "4  New York   \n",
      "\n",
      "Cleaned KC Housing Data:\n",
      "       price  bedrooms  bathrooms  sqft_living                    street  \\\n",
      "0   313000.0       3.0       1.50         1340      18810 Densmore Ave N   \n",
      "1  2384000.0       5.0       2.50         3650           709 W Blaine St   \n",
      "2   342000.0       3.0       2.00         1930  26206-26214 143rd Ave SE   \n",
      "3   420000.0       3.0       2.25         2000           857 170th Pl NE   \n",
      "4   550000.0       4.0       2.50         1940         9105 170th Ave NE   \n",
      "\n",
      "        city  statezip  \n",
      "0  Shoreline  WA 98133  \n",
      "1    Seattle  WA 98119  \n",
      "2       Kent  WA 98042  \n",
      "3   Bellevue  WA 98008  \n",
      "4    Redmond  WA 98052   \n",
      "\n",
      "Cleaned House Price Prediction Data:\n",
      "   Area  Bedrooms  Bathrooms   Price\n",
      "0  1360         5          4  149919\n",
      "1  4272         5          4  424998\n",
      "2  3592         2          2  266746\n",
      "3   966         4          2  244020\n",
      "4  4926         1          4  636056 \n",
      "\n",
      "Cleaned and Reduced Realtor Data (12,000 entries):\n",
      "            price  bed  bath  acre_lot             city       state  zip_code\n",
      "79257    609900.0  3.0   2.0      0.92  Bridgewater Twp  New Jersey    8807.0\n",
      "753021   219900.0  4.0   3.0      5.00      Grand Ledge    Michigan   48837.0\n",
      "809872   499900.0  3.0   2.0      6.07        Greenwood   Wisconsin   54437.0\n",
      "1755690  239900.0  4.0   2.0      0.49        Knoxville   Tennessee   37923.0\n",
      "1279063  429900.0  3.0   1.0      0.16   San Bernardino  California   92405.0 \n",
      "\n",
      "Realtor Data Reduced Shape: (12000, 7)\n"
     ]
    }
   ],
   "source": [
    "# Print the cleaned American Housing Data\n",
    "print(\"Cleaned American Housing Data:\")\n",
    "print(american_housing_data_cleaned.head(), \"\\n\")\n",
    "\n",
    "# Print the cleaned KC Housing Data\n",
    "print(\"Cleaned KC Housing Data:\")\n",
    "print(kc_housing_data_cleaned.head(), \"\\n\")\n",
    "\n",
    "# Print the cleaned House Price Prediction Data\n",
    "print(\"Cleaned House Price Prediction Data:\")\n",
    "print(house_price_data_cleaned.head(), \"\\n\")\n",
    "\n",
    "# Print the cleaned and reduced Realtor Data (to 12,000 entries)\n",
    "print(\"Cleaned and Reduced Realtor Data (12,000 entries):\")\n",
    "print(realtor_reduced.head(), \"\\n\")\n",
    "\n",
    "# Check the shape of the reduced realtor dataset to ensure it has 12,000 rows\n",
    "print(\"Realtor Data Reduced Shape:\", realtor_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c21d61e-5342-4b9b-bc1c-b2fa670ea1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitched Dataset:\n",
      "   Zip Code      Price  Beds  Baths  Living Space      City     State  \\\n",
      "0   10013.0  3999000.0   2.0    3.0        1967.0  New York  New York   \n",
      "1   10013.0  3999000.0   2.0    3.0        1967.0  New York  New York   \n",
      "2   10014.0  1650000.0   1.0    1.0         718.0  New York  New York   \n",
      "3   10014.0   760000.0   3.0    2.0        1538.0  New York  New York   \n",
      "4   10014.0  1100000.0   1.0    1.0         600.0  New York  New York   \n",
      "\n",
      "     County  price  bedrooms  ...  city  statezip Area Bedrooms Bathrooms  \\\n",
      "0  New York    NaN       NaN  ...   NaN       NaN  NaN      NaN       NaN   \n",
      "1  New York    NaN       NaN  ...   NaN       NaN  NaN      NaN       NaN   \n",
      "2  New York    NaN       NaN  ...   NaN       NaN  NaN      NaN       NaN   \n",
      "3  New York    NaN       NaN  ...   NaN       NaN  NaN      NaN       NaN   \n",
      "4  New York    NaN       NaN  ...   NaN       NaN  NaN      NaN       NaN   \n",
      "\n",
      "   bed  bath  acre_lot  state  zip_code  \n",
      "0  NaN   NaN       NaN    NaN       NaN  \n",
      "1  NaN   NaN       NaN    NaN       NaN  \n",
      "2  NaN   NaN       NaN    NaN       NaN  \n",
      "3  NaN   NaN       NaN    NaN       NaN  \n",
      "4  NaN   NaN       NaN    NaN       NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Stitched Data Shape: (58581, 23)\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the cleaned datasets\n",
    "stitched_data = pd.concat([american_housing_data_cleaned, kc_housing_data_cleaned, \n",
    "                           house_price_data_cleaned, realtor_reduced], axis=0, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the stitched dataset to verify\n",
    "print(\"Stitched Dataset:\")\n",
    "print(stitched_data.head())\n",
    "\n",
    "# Check the shape of the stitched dataset to verify the number of rows and columns\n",
    "print(\"Stitched Data Shape:\", stitched_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "210cc143-c16d-49a5-97e9-27f774446fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Zip Code      Price  Beds  Baths  Living Space      City     State  \\\n",
      "0   10013.0  3999000.0   2.0    3.0        1967.0  New York  New York   \n",
      "1   10013.0  3999000.0   2.0    3.0        1967.0  New York  New York   \n",
      "2   10014.0  1650000.0   1.0    1.0         718.0  New York  New York   \n",
      "3   10014.0   760000.0   3.0    2.0        1538.0  New York  New York   \n",
      "4   10014.0  1100000.0   1.0    1.0         600.0  New York  New York   \n",
      "\n",
      "     County  price  bedrooms  ...  city  statezip Area Bedrooms Bathrooms  \\\n",
      "0  New York    NaN       NaN  ...   NaN       NaN  NaN      NaN       NaN   \n",
      "1  New York    NaN       NaN  ...   NaN       NaN  NaN      NaN       NaN   \n",
      "2  New York    NaN       NaN  ...   NaN       NaN  NaN      NaN       NaN   \n",
      "3  New York    NaN       NaN  ...   NaN       NaN  NaN      NaN       NaN   \n",
      "4  New York    NaN       NaN  ...   NaN       NaN  NaN      NaN       NaN   \n",
      "\n",
      "   bed  bath  acre_lot  state  zip_code  \n",
      "0  NaN   NaN       NaN    NaN       NaN  \n",
      "1  NaN   NaN       NaN    NaN       NaN  \n",
      "2  NaN   NaN       NaN    NaN       NaN  \n",
      "3  NaN   NaN       NaN    NaN       NaN  \n",
      "4  NaN   NaN       NaN    NaN       NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN values with defaults\n",
    "stitched_data_filled = stitched_data.fillna({\n",
    "    'Price': 0,\n",
    "    'Beds': 0,\n",
    "    'Baths': 0,\n",
    "    'City': 'Unknown',\n",
    "    'State': 'Unknown',\n",
    "    # Add more column-specific default values if needed\n",
    "})\n",
    "\n",
    "# Display the first few rows after filling NaNs\n",
    "print(stitched_data_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0302fbd8-ef7b-4177-bd99-a7a68c088c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitched Dataset with Standardized Column Names:\n",
      "   zipcode      price  bedrooms  bathrooms  sqft_living      city     state  \\\n",
      "0  10013.0  3999000.0       2.0        3.0       1967.0  New York  New York   \n",
      "1  10013.0  3999000.0       2.0        3.0       1967.0  New York  New York   \n",
      "2  10014.0  1650000.0       1.0        1.0        718.0  New York  New York   \n",
      "3  10014.0   760000.0       3.0        2.0       1538.0  New York  New York   \n",
      "4  10014.0  1100000.0       1.0        1.0        600.0  New York  New York   \n",
      "\n",
      "     county street statezip  bed  bath  lot_size  \n",
      "0  New York    NaN      NaN  NaN   NaN       NaN  \n",
      "1  New York    NaN      NaN  NaN   NaN       NaN  \n",
      "2  New York    NaN      NaN  NaN   NaN       NaN  \n",
      "3  New York    NaN      NaN  NaN   NaN       NaN  \n",
      "4  New York    NaN      NaN  NaN   NaN       NaN  \n",
      "Stitched Data Shape: (58581, 13)\n",
      "Stitched Data after Filling NaNs:\n",
      "   zipcode      price  bedrooms  bathrooms  sqft_living      city     state  \\\n",
      "0  10013.0  3999000.0       2.0        3.0       1967.0  New York  New York   \n",
      "1  10013.0  3999000.0       2.0        3.0       1967.0  New York  New York   \n",
      "2  10014.0  1650000.0       1.0        1.0        718.0  New York  New York   \n",
      "3  10014.0   760000.0       3.0        2.0       1538.0  New York  New York   \n",
      "4  10014.0  1100000.0       1.0        1.0        600.0  New York  New York   \n",
      "\n",
      "     county street statezip  bed  bath  lot_size  \n",
      "0  New York    NaN      NaN  NaN   NaN       NaN  \n",
      "1  New York    NaN      NaN  NaN   NaN       NaN  \n",
      "2  New York    NaN      NaN  NaN   NaN       NaN  \n",
      "3  New York    NaN      NaN  NaN   NaN       NaN  \n",
      "4  New York    NaN      NaN  NaN   NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Define a standard set of column names\n",
    "column_mapping = {\n",
    "    'Zip Code': 'zipcode',\n",
    "    'Price': 'price',\n",
    "    'Beds': 'bedrooms',\n",
    "    'Baths': 'bathrooms',\n",
    "    'Living Space': 'sqft_living',\n",
    "    'City': 'city',\n",
    "    'State': 'state',\n",
    "    'County': 'county',\n",
    "    'Area': 'sqft_living',  # Assuming \"Area\" refers to living space\n",
    "    'Bedrooms': 'bedrooms',\n",
    "    'Bathrooms': 'bathrooms',\n",
    "    'street': 'street',\n",
    "    'statezip': 'statezip',  # Already aligned\n",
    "    'acre_lot': 'lot_size',  # Align acre lot with lot size\n",
    "    'zip_code': 'zipcode'\n",
    "}\n",
    "\n",
    "# Apply the mapping to each dataset before stitching\n",
    "american_housing_data_cleaned = american_housing_data_cleaned.rename(columns=column_mapping)\n",
    "kc_housing_data_cleaned = kc_housing_data_cleaned.rename(columns=column_mapping)\n",
    "house_price_data_cleaned = house_price_data_cleaned.rename(columns=column_mapping)\n",
    "realtor_reduced = realtor_reduced.rename(columns=column_mapping)\n",
    "\n",
    "# Now stitch the datasets together again\n",
    "stitched_data_standardized = pd.concat([american_housing_data_cleaned, kc_housing_data_cleaned, \n",
    "                                        house_price_data_cleaned, realtor_reduced], axis=0, ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the stitched dataset to verify\n",
    "print(\"Stitched Dataset with Standardized Column Names:\")\n",
    "print(stitched_data_standardized.head())\n",
    "\n",
    "# Check the shape of the stitched dataset\n",
    "print(\"Stitched Data Shape:\", stitched_data_standardized.shape)\n",
    "\n",
    "# Now fill NaN values after standardizing\n",
    "stitched_data_filled = stitched_data_standardized.fillna({\n",
    "    'price': 1000000.0,\n",
    "    'bedrooms': 3,\n",
    "    'bathrooms': 3,\n",
    "    'city': 'Unknown',\n",
    "    'state': 'Unknown'\n",
    "})\n",
    "\n",
    "# Display the result after filling NaN values\n",
    "print(\"Stitched Data after Filling NaNs:\")\n",
    "print(stitched_data_filled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88f58bf7-6b53-4a4a-91cd-5514ad3b43b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitched Data after Filling NaNs and Dropping Rows:\n",
      "   zipcode      price  bedrooms  bathrooms  sqft_living      city     state  \\\n",
      "0  10013.0  3999000.0       2.0        3.0       1967.0  New York  New York   \n",
      "1  10013.0  3999000.0       2.0        3.0       1967.0  New York  New York   \n",
      "2  10014.0  1650000.0       1.0        1.0        718.0  New York  New York   \n",
      "3  10014.0   760000.0       3.0        2.0       1538.0  New York  New York   \n",
      "4  10014.0  1100000.0       1.0        1.0        600.0  New York  New York   \n",
      "\n",
      "     county   street statezip  bed  bath  \n",
      "0  New York  Unknown      NaN  NaN   NaN  \n",
      "1  New York  Unknown      NaN  NaN   NaN  \n",
      "2  New York  Unknown      NaN  NaN   NaN  \n",
      "3  New York  Unknown      NaN  NaN   NaN  \n",
      "4  New York  Unknown      NaN  NaN   NaN  \n",
      "Stitched Data Shape after Cleaning: (58581, 12)\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'lot_size' column\n",
    "stitched_data_standardized = stitched_data_standardized.drop(columns=['lot_size'], errors='ignore')\n",
    "\n",
    "# Fill NaN values with the specified defaults\n",
    "stitched_data_filled = stitched_data_standardized.fillna({\n",
    "    'price': 1000000.0,    # Fill missing prices with 1,000,000\n",
    "    'bedrooms': 3,         # Fill missing bedrooms with 3\n",
    "    'bathrooms': 3,        # Fill missing bathrooms with 3\n",
    "    'sqft_living': 2500,   # Fill missing sqft living with 2,500\n",
    "    'city': 'Unknown',     # Fill missing city names with 'Unknown'\n",
    "    'state': 'Unknown',    # Fill missing state names with 'Unknown'\n",
    "    'zipcode': 'Unknown',  # Fill missing zip codes with 'Unknown'\n",
    "    'county': 'Unknown',   # Fill missing county with 'Unknown'\n",
    "    'street': 'Unknown',   # Fill missing street with 'Unknown'\n",
    "})\n",
    "\n",
    "# Drop rows with more than 50% missing values\n",
    "threshold = len(stitched_data_filled.columns) * 0.5\n",
    "stitched_data_cleaned = stitched_data_filled.dropna(thresh=threshold)\n",
    "\n",
    "# Display the first few rows after filling NaNs and dropping rows with too many NaNs\n",
    "print(\"Stitched Data after Filling NaNs and Dropping Rows:\")\n",
    "print(stitched_data_cleaned.head())\n",
    "\n",
    "# Check the shape to confirm the number of rows and columns after cleaning\n",
    "print(\"Stitched Data Shape after Cleaning:\", stitched_data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b05a848-3332-4db6-923e-249f3b83b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitched Data after Cleaning:\n",
      "   zipcode      price  bedrooms  bathrooms  sqft_living      city     state  \\\n",
      "0  10013.0  3999000.0       2.0        3.0       1967.0  New York  New York   \n",
      "1  10013.0  3999000.0       2.0        3.0       1967.0  New York  New York   \n",
      "2  10014.0  1650000.0       1.0        1.0        718.0  New York  New York   \n",
      "3  10014.0   760000.0       3.0        2.0       1538.0  New York  New York   \n",
      "4  10014.0  1100000.0       1.0        1.0        600.0  New York  New York   \n",
      "\n",
      "     county   street statezip  bed  bath  \n",
      "0  New York  Unknown      NaN  NaN   NaN  \n",
      "1  New York  Unknown      NaN  NaN   NaN  \n",
      "2  New York  Unknown      NaN  NaN   NaN  \n",
      "3  New York  Unknown      NaN  NaN   NaN  \n",
      "4  New York  Unknown      NaN  NaN   NaN  \n",
      "Stitched Data Shape after Cleaning: (58581, 12)\n"
     ]
    }
   ],
   "source": [
    "# Drop redundant columns 'beds' and 'baths' if they exist\n",
    "stitched_data_standardized = stitched_data_standardized.drop(columns=['beds', 'baths'], errors='ignore')\n",
    "\n",
    "# Fill NaN values with the specified defaults again after cleaning up columns\n",
    "stitched_data_filled = stitched_data_standardized.fillna({\n",
    "    'price': 1000000.0,    # Fill missing prices with 1,000,000\n",
    "    'bedrooms': 3,         # Fill missing bedrooms with 3\n",
    "    'bathrooms': 3,        # Fill missing bathrooms with 3\n",
    "    'sqft_living': 2500,   # Fill missing sqft living with 2,500\n",
    "    'city': 'Unknown',     # Fill missing city names with 'Unknown'\n",
    "    'state': 'Unknown',    # Fill missing state names with 'Unknown'\n",
    "    'zipcode': 'Unknown',  # Fill missing zip codes with 'Unknown'\n",
    "    'county': 'Unknown',   # Fill missing county with 'Unknown'\n",
    "    'street': 'Unknown',   # Fill missing street with 'Unknown'\n",
    "})\n",
    "\n",
    "# Drop rows with more than 50% missing values\n",
    "threshold = len(stitched_data_filled.columns) * 0.5\n",
    "stitched_data_cleaned = stitched_data_filled.dropna(thresh=threshold)\n",
    "\n",
    "# Display the cleaned data\n",
    "print(\"Stitched Data after Cleaning:\")\n",
    "print(stitched_data_cleaned.head())\n",
    "\n",
    "# Check the shape to confirm the number of rows and columns after cleaning\n",
    "print(\"Stitched Data Shape after Cleaning:\", stitched_data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3097799c-e440-4ebd-89dc-ba0710a9634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitched Data after Cleaning:\n",
      "   zipcode      price  bedrooms  bathrooms  sqft_living      city     state  \\\n",
      "0  10013.0  3999000.0       2.0        3.0       1967.0  New York  New York   \n",
      "1  10013.0  3999000.0       2.0        3.0       1967.0  New York  New York   \n",
      "2  10014.0  1650000.0       1.0        1.0        718.0  New York  New York   \n",
      "3  10014.0   760000.0       3.0        2.0       1538.0  New York  New York   \n",
      "4  10014.0  1100000.0       1.0        1.0        600.0  New York  New York   \n",
      "\n",
      "     county  \n",
      "0  New York  \n",
      "1  New York  \n",
      "2  New York  \n",
      "3  New York  \n",
      "4  New York  \n",
      "Stitched Data Shape after Cleaning: (58581, 8)\n"
     ]
    }
   ],
   "source": [
    "# Drop 'bed', 'bath', 'statezip', and 'street' if redundant or unnecessary\n",
    "columns_to_drop = ['bed', 'bath', 'statezip', 'street']\n",
    "\n",
    "# Ensure critical columns remain (like state, zipcode, bedrooms, and bathrooms)\n",
    "stitched_data_standardized = stitched_data_standardized.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Fill NaN values with the specified defaults again after dropping columns\n",
    "stitched_data_filled = stitched_data_standardized.fillna({\n",
    "    'price': 1000000.0,    # Fill missing prices with 1,000,000\n",
    "    'bedrooms': 3,         # Fill missing bedrooms with 3\n",
    "    'bathrooms': 3,        # Fill missing bathrooms with 3\n",
    "    'sqft_living': 2500,   # Fill missing sqft living with 2,500\n",
    "    'city': 'Unknown',     # Fill missing city names with 'Unknown'\n",
    "    'state': 'Unknown',    # Fill missing state names with 'Unknown'\n",
    "    'zipcode': 'Unknown',  # Fill missing zip codes with 'Unknown'\n",
    "    'county': 'Unknown',   # Fill missing county with 'Unknown'\n",
    "})\n",
    "\n",
    "# Drop rows with more than 50% missing values\n",
    "threshold = len(stitched_data_filled.columns) * 0.5\n",
    "stitched_data_cleaned = stitched_data_filled.dropna(thresh=threshold)\n",
    "\n",
    "# Display the first few rows after cleaning\n",
    "print(\"Stitched Data after Cleaning:\")\n",
    "print(stitched_data_cleaned.head())\n",
    "\n",
    "# Check the shape to confirm the number of rows and columns after cleaning\n",
    "print(\"Stitched Data Shape after Cleaning:\", stitched_data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ee18f1b-2eb3-4882-bf9f-496a0b64bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in S3 bucket:\n",
      "American_Housing_Data_20231209.csv\n",
      "House Price Prediction Dataset.csv\n",
      "KC_housing_data.csv\n",
      "adult.csv\n",
      "clarify-output/analysis.json\n",
      "clarify-output/analysis_config.json\n",
      "clarify-output/report.html\n",
      "clarify-output/report.ipynb\n",
      "clarify-output/report.pdf\n",
      "cleaned_adult.csv/cleaned_adult.csv\n",
      "inference.py\n",
      "iris_test.csv/iris_test.csv\n",
      "iris_train.csv/iris_train.csv\n",
      "logistic_regression_model.joblib\n",
      "logistic_regression_model.tar.gz\n",
      "models/xgboost_titanic_model.json\n",
      "models/xgboost_titanic_model.tar.gz\n",
      "realtor-data.zip.csv\n",
      "sagemaker-xgboost-2024-10-12-22-19-14-806/source/sourcedir.tar.gz\n",
      "titanic/titanic_processed.csv\n",
      "titanic_test.csv/titanic_test.csv\n",
      "titanic_train.csv/titanic_train.csv\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-00-32-686/debug-output/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-00-32-686/profiler-output/framework/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-00-32-686/profiler-output/system/incremental/2024101222/1728770460.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-00-32-686/profiler-output/system/incremental/2024101222/1728770520.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-00-32-686/profiler-output/system/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-06-10-845/debug-output/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-06-10-845/profiler-output/framework/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-06-10-845/profiler-output/system/incremental/2024101222/1728770760.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-06-10-845/profiler-output/system/incremental/2024101222/1728770820.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-06-10-845/profiler-output/system/incremental/2024101222/1728770880.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-06-10-845/profiler-output/system/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-19-14-806/debug-output/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-19-14-806/profiler-output/framework/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-19-14-806/profiler-output/system/incremental/2024101222/1728771540.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-19-14-806/profiler-output/system/incremental/2024101222/1728771600.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-19-14-806/profiler-output/system/incremental/2024101222/1728771660.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-19-14-806/profiler-output/system/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-23-46-466/debug-output/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-23-46-466/profiler-output/framework/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-23-46-466/profiler-output/system/incremental/2024101222/1728771840.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-23-46-466/profiler-output/system/incremental/2024101222/1728771900.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-23-46-466/profiler-output/system/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-29-25-206/debug-output/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-29-25-206/profiler-output/framework/training_job_end.ts\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-29-25-206/profiler-output/system/incremental/2024101222/1728772200.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-29-25-206/profiler-output/system/incremental/2024101222/1728772260.algo-1.json\n",
      "xgboost-output/sagemaker-xgboost-2024-10-12-22-29-25-206/profiler-output/system/training_job_end.ts\n"
     ]
    }
   ],
   "source": [
    "# List all files in the S3 bucket\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "# Print the file names (keys)\n",
    "print(\"Files in S3 bucket:\")\n",
    "for item in response.get('Contents', []):\n",
    "    print(item['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfd929f2-db54-44c0-a91c-4ebc9d67c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stitched dataset uploaded to S3!\n"
     ]
    }
   ],
   "source": [
    "# Save the stitched dataset locally\n",
    "stitched_file = 'stitched_final_cleaned_data.csv'\n",
    "stitched_data_cleaned.to_csv(stitched_file, index=False)\n",
    "\n",
    "# Now upload the stitched dataset to S3\n",
    "s3.upload_file(stitched_file, bucket_name, stitched_file)\n",
    "print(\"Stitched dataset uploaded to S3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efc78fa1-2a77-425b-8ffe-64d2f18988f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error lines received while fetching: error: failed to push some refs to 'https://github.com/ScottReidux/aai-540.git'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets uploaded to GitHub successfully!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import git\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# GitHub Personal Access Token\n",
    "github_token = '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'\n",
    "\n",
    "# Set up S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# S3 bucket and file details\n",
    "bucket_name = 'christimoncriefbucket-v2'\n",
    "s3_files = [\n",
    "    'American_Housing_Data_20231209.csv',\n",
    "    'House Price Prediction Dataset.csv',\n",
    "    'KC_housing_data.csv',\n",
    "    'realtor-data.zip.csv',\n",
    "    'stitched_final_cleaned_data.csv'\n",
    "]\n",
    "\n",
    "# Temporary folder to store downloaded datasets\n",
    "local_download_dir = '/tmp/datasets'\n",
    "os.makedirs(local_download_dir, exist_ok=True)\n",
    "\n",
    "# Download each file from S3\n",
    "for s3_file in s3_files:\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=s3_file)\n",
    "    local_file_path = os.path.join(local_download_dir, s3_file)\n",
    "    with open(local_file_path, 'wb') as f:\n",
    "        f.write(obj['Body'].read())\n",
    "\n",
    "# GitHub repository URL with authentication token\n",
    "repo_url = f'https://{github_token}@github.com/ScottReidux/aai-540.git'\n",
    "local_repo_dir = '/tmp/aai-540'  # Temporary directory for cloning the repo\n",
    "\n",
    "# Clone the GitHub repo\n",
    "if os.path.exists(local_repo_dir):\n",
    "    shutil.rmtree(local_repo_dir)\n",
    "repo = git.Repo.clone_from(repo_url, local_repo_dir)\n",
    "\n",
    "# Pull latest changes from the remote repository (to avoid conflicts)\n",
    "origin = repo.remote(name='origin')\n",
    "origin.pull('main')\n",
    "\n",
    "# Copy the downloaded files to the cloned repository directory\n",
    "for dataset in s3_files:\n",
    "    shutil.copy(os.path.join(local_download_dir, dataset), local_repo_dir)\n",
    "\n",
    "# Add and commit the datasets to the GitHub repo\n",
    "repo.index.add([os.path.join(local_repo_dir, dataset) for dataset in s3_files])\n",
    "repo.index.commit(\"Added original and stitched datasets from S3\")\n",
    "\n",
    "# Push the changes to GitHub\n",
    "origin.push()\n",
    "\n",
    "print(\"Datasets uploaded to GitHub successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564934bc-99a5-4032-a1c3-9f35de5f6c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
